{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group level statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving First-Level results\n",
    "As we now have the same contrast from multiple `subjects`, we can define our `group level model`. At first, we need to gather the `individual contrast maps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bids.layout import BIDSLayout\n",
    "\n",
    "ds_path = 'FaceRecognition'\n",
    "# Initialize the BIDS layout and include the derivatives in it\n",
    "layout = BIDSLayout(os.path.join(ds_path, 'data/bids'), derivatives = True)\n",
    "layout.add_derivatives(os.path.join(ds_path, \"results\", \"first-level-2mm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's collect individual t-maps (`stat`) that represent the BOLD activity estimate divided by the uncertainty about this estimate. \n",
    "\n",
    "Let's first look at only the **Faces > Scrambled** contrast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = 'FacesScrambled'\n",
    "stat_files = layout.get(desc = contrast, suffix='stat', extension = '.nii.gz')\n",
    "print(*stat_files, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to display subject ID on top of their individual t-maps. Therefore we need to link each stat file with the corresponding subject ID. There are several ways to do this. The simplest seems to retrieve the subject list from the BIDS layout. But `PyBIDS` returns unsorted subject list, that's a bit problematic. And for some reason, sort() does not work on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layout.get_subjects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore I will sort it this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = sorted(list(set([f.get_entities().get(\"subject\") for f in stat_files])))\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying subject t-maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.glm.thresholding import threshold_stats_img\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(14, 14))\n",
    "\n",
    "for i, stat_map in enumerate(stat_files):\n",
    "    # get thresholded t-map\n",
    "    cluster_map, threshold = threshold_stats_img(stat_map, alpha=.001, height_control='fpr', cluster_threshold=20)\n",
    "    # plot the thresholded map\n",
    "    plotting.plot_glass_brain(cluster_map, \n",
    "                              title = 'sub-' + subjects[i],\n",
    "                              axes = axes[int(i / 4), int(i % 4)],\n",
    "                              plot_abs = False, \n",
    "                              display_mode='x', \n",
    "                             threshold=threshold)\n",
    "fig.suptitle(contrast + ' t-map (unc. p<.001, k=20)')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate second level model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step includes the definition of a `design matrix`. Here we will want to run a simple `one-sample t-test`. We just need to indicate as many `1` as we have subjects with first-level results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "design_matrix = pd.DataFrame(\n",
    "    [1] * len(stat_files),\n",
    "    columns=['intercept'])\n",
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model specification and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm = 8.0)\n",
    "second_level_model = second_level_model.fit(\n",
    "    stat_files,\n",
    "    design_matrix = design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = second_level_model.compute_contrast(output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map, threshold = threshold_stats_img(\n",
    "    z_map, alpha=0.001, \n",
    "    height_control='fpr', \n",
    "    cluster_threshold=20)\n",
    "\n",
    "from nilearn.datasets import load_mni152_template\n",
    "template = load_mni152_template()\n",
    "print('Uncorrected p<.001 threshold: %.3f' % threshold)\n",
    "plotting.plot_stat_map(\n",
    "    cluster_map, \n",
    "    threshold = threshold,       \n",
    "    display_mode = 'ortho',\n",
    "   cut_coords = [37,-84,-8],\n",
    "    black_bg = True,\n",
    "    bg_img = template,\n",
    "    title = contrast + ' (unc. p<.001, k=20)')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, threshold = threshold_stats_img(\n",
    "    z_map, alpha=0.05, \n",
    "    height_control='bonferroni', \n",
    "    cluster_threshold=0,\n",
    "    two_sided=False)\n",
    "\n",
    "from nilearn.datasets import load_mni152_template\n",
    "template = load_mni152_template()\n",
    "\n",
    "print('FWE p<.05 threshold: %.3f' % threshold)\n",
    "plotting.plot_stat_map(\n",
    "    cluster_map, \n",
    "    threshold = threshold,       \n",
    "    display_mode = 'ortho',\n",
    "    cut_coords = [37,-62,-14],\n",
    "    black_bg = True,\n",
    "    bg_img = template,\n",
    "    title = contrast + ' (FWE p<.05)')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at a 3D brain using `ploty`. You might need to install it first (`pip inatall plotly`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "\n",
    "_, threshold = threshold_stats_img(\n",
    "    z_map, alpha = 0.001, \n",
    "    height_control = 'fpr',\n",
    "    two_sided = True)\n",
    "\n",
    "view = plotting.view_img_on_surf(cluster_map, threshold=threshold)\n",
    "# view.open_in_browser()\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more summary results. Here we will get a cluster table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import get_clusters_table\n",
    "get_clusters_table(z_map, threshold, cluster_threshold=20, two_sided=False, min_distance=8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can create more complete reports with [nilearn.reporting](https://nilearn.github.io/dev/modules/generated/nilearn.reporting.make_glm_report.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from nilearn.reporting import make_glm_report\n",
    "\n",
    "report = make_glm_report(model = second_level_model,\n",
    "                         contrasts = 'intercept',\n",
    "                         threshold = 3,\n",
    "                         cluster_threshold = 30,\n",
    "                         display_mode = 'ortho'\n",
    "                         )\n",
    "\n",
    "report\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use ['atlasreader'](https://github.com/miykael/atlasreader) package, which I will in the below script to create reports for all our contrasts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second level for multiple contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import warnings;\n",
    "#warnings.filterwarnings('ignore');\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# ======================================================================\n",
    "# Dace ApÅ¡valka (MRC CBU 2022)\n",
    "# First level fMRI analysis using Nilearn\n",
    "# ======================================================================\n",
    "\n",
    "# ======================================================================\n",
    "# IMPORT RELEVANT PACKAGES\n",
    "# ======================================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bids.layout import BIDSLayout\n",
    "from nilearn.datasets import load_mni152_template\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from atlasreader import create_output\n",
    "\n",
    "# ======================================================================\n",
    "# DEFINE PATHS\n",
    "# ======================================================================\n",
    "ds_path = 'FaceRecognition'\n",
    "outdir = os.path.join(ds_path, 'results', 'group-level')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# ======================================================================\n",
    "# WHICH CONTRASTS\n",
    "# ======================================================================\n",
    "contrasts = {'FamousUnfamiliar': 'Famous > Unfamiliar',\n",
    "             'UnfamiliarFamous': 'Unfamiliar > Famous',\n",
    "             'FacesScrambled': 'Faces > Scrambled',\n",
    "             'ScrambledFaces': 'Scrambled > Faces',\n",
    "             'EffectsOfInterest': 'Effects of interest'}\n",
    "\n",
    "# ======================================================================\n",
    "# PREPARE OTHER SUFF\n",
    "# ======================================================================\n",
    "\n",
    "# Initialize the BIDS layout and include the derivatives in it\n",
    "layout = BIDSLayout(os.path.join(ds_path, 'data/bids'), derivatives=True)\n",
    "layout.add_derivatives(os.path.join(ds_path, \"results\", \"first-level-2mm\"))\n",
    "\n",
    "# load a template to resample images to if needed\n",
    "template = load_mni152_template()\n",
    "\n",
    "# ======================================================================\n",
    "# PERFORM GROUP LEVEL ANALYSIS PER CONTRAST\n",
    "# ======================================================================\n",
    "\n",
    "for contrast_id, contrast_val in contrasts.items():\n",
    "    stat_files = layout.get(desc = contrast_id, suffix = 'stat', extension = '.nii.gz')\n",
    "    result_name = 'group_zmap_' + contrast_id + '_unc001k20'\n",
    "      \n",
    "    design_matrix = pd.DataFrame([1] * len(stat_files),\n",
    "                                 columns=['intercept'])\n",
    "    \n",
    "    second_level_model = SecondLevelModel(smoothing_fwhm = 8.0)\n",
    "    second_level_model = second_level_model.fit(\n",
    "        stat_files,\n",
    "        design_matrix = design_matrix)\n",
    "    \n",
    "    z_map = second_level_model.compute_contrast(output_type='z_score')\n",
    "        \n",
    "    # get threshold\n",
    "    cluster_map, threshold = threshold_stats_img(z_map, alpha=.05, height_control='fpr', cluster_threshold=20)\n",
    "    # get peak clusters    \n",
    "    peaks = get_clusters_table(z_map, stat_threshold=threshold, cluster_threshold=20)\n",
    "    \n",
    "    # if there are significant voxels, then save the img and the plot\n",
    "    try: \n",
    "        peak_xyz = peaks.loc[0, ['X','Y','Z']]\n",
    "        # create plot\n",
    "        plotting.plot_stat_map(\n",
    "            cluster_map,\n",
    "            threshold = threshold, \n",
    "            display_mode='ortho',\n",
    "            cut_coords = peak_xyz, \n",
    "            black_bg = True, \n",
    "            title = contrast_val + ' unc. p<.001, k=20'\n",
    "        )\n",
    "        \n",
    "        plt.show()\n",
    "        # save results                   \n",
    "        z_map.to_filename(os.path.join(outdir, result_name + '.nii.gz'))\n",
    "    except KeyError:\n",
    "        print('\\t', contrast_val, 'has no significant voxels.')      \n",
    "    \n",
    "    # generate and save also atlasreader output\n",
    "    create_output(\n",
    "        os.path.join(outdir, result_name + '.nii.gz'), \n",
    "        cluster_extent = 20, \n",
    "        voxel_thresh = threshold,\n",
    "        outdir = os.path.join(outdir, 'atlasreader', contrast_id)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "874.85px",
    "left": "2183px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

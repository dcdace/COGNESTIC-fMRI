{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group level statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving First-Level results\n",
    "As we now have the same contrast from multiple `subjects` we can define our `group level model`. At first, we need to gather the `individual contrast maps`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bids.layout import BIDSLayout\n",
    "\n",
    "ds_path = 'FaceRecognition'\n",
    "# Initialize the BIDS layout and include the derivatives in it\n",
    "layout = BIDSLayout(os.path.join(ds_path, 'data/bids'), derivatives=True)\n",
    "layout.add_derivatives(os.path.join(ds_path, \"results\", \"first-level-2mm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will collect individual t-maps that represent the BOLD activity estimate divided by the uncertainty about this estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BIDSImageFile filename='/imaging/correia/dace/training/summer-school/COGNESTIC-fMRI/hands-on/FaceRecognition/results/first-level-2mm/sub-03/sub-03_task-facerecognition_desc-FacesScrambled_stat.nii.gz'>\n",
      "<BIDSImageFile filename='/imaging/correia/dace/training/summer-school/COGNESTIC-fMRI/hands-on/FaceRecognition/results/first-level-2mm/sub-04/sub-04_task-facerecognition_desc-FacesScrambled_stat.nii.gz'>\n"
     ]
    }
   ],
   "source": [
    "contrast = 'FacesScrambled'\n",
    "stat_files = layout.get(desc = contrast, suffix='stat', extension = '.nii.gz')\n",
    "print(*stat_files, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyBIDS` returns unsorted subject list, that's a bit problematic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layout.get_subjects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = sorted(list(set([f.get_entities().get(\"subject\") for f in stat_files])))\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying subject t-maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.glm.thresholding import threshold_stats_img\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(14, 14))\n",
    "\n",
    "for i, stat_map in enumerate(stat_files):\n",
    "    cluster_map, threshold = threshold_stats_img(stat_map, alpha=.001, height_control='fpr', cluster_threshold=20)\n",
    "    plotting.plot_glass_brain(stat_map.path, \n",
    "                              title = 'sub-' + subjects[i],\n",
    "                              axes = axes[int(i / 4), int(i % 4)],\n",
    "                              plot_abs = False, \n",
    "                              display_mode='x', \n",
    "                             threshold=threshold)\n",
    "fig.suptitle(contrast + ' t-map (unc. p<.001, k=20)')\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate second level model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step includes the definition of a `design matrix`. Here we will want to run a simple `one-sample t-test`. We just need to indicate as many `1` as we have subjects with first-level results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "design_matrix = pd.DataFrame(\n",
    "    [1] * len(stat_files),\n",
    "    columns=['intercept'])\n",
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model specification and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "\n",
    "second_level_model = SecondLevelModel(smoothing_fwhm = 8.0)\n",
    "second_level_model = second_level_model.fit(\n",
    "    stat_files,\n",
    "    design_matrix = design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = second_level_model.compute_contrast(output_type='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map, threshold = threshold_stats_img(\n",
    "    z_map, alpha=0.001, \n",
    "    height_control='fpr', \n",
    "    cluster_threshold=20)\n",
    "\n",
    "from nilearn.datasets import load_mni152_template\n",
    "template = load_mni152_template()\n",
    "print('Uncorrected p<.001 threshold: %.3f' % threshold)\n",
    "plotting.plot_stat_map(\n",
    "    cluster_map, \n",
    "    threshold = threshold,       \n",
    "    display_mode = 'ortho',\n",
    "   cut_coords = [37,-84,-8],\n",
    "    black_bg = True,\n",
    "    bg_img = template,\n",
    "    title = contrast + ' (unc. p<.001, k=20)')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import get_clusters_table\n",
    "get_clusters_table(z_map, threshold, cluster_threshold=20, two_sided=False, min_distance=8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from nilearn.reporting import make_glm_report\n",
    "\n",
    "report = make_glm_report(model = second_level_model,\n",
    "                         contrasts = 'intercept',\n",
    "                         threshold = 3,\n",
    "                         cluster_threshold = 30,\n",
    "                         display_mode = 'ortho'\n",
    "                         )\n",
    "\n",
    "report\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlasreader https://github.com/miykael/atlasreader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second level for multiple contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# ======================================================================\n",
    "# Dace ApÅ¡valka (MRC CBU 2022)\n",
    "# First level fMRI analysis using Nilearn\n",
    "# ======================================================================\n",
    "\n",
    "# ======================================================================\n",
    "# IMPORT RELEVANT PACKAGES\n",
    "# ======================================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bids.layout import BIDSLayout\n",
    "from nilearn.datasets import load_mni152_template\n",
    "from nilearn.image import resample_to_img\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from atlasreader import create_output\n",
    "\n",
    "# ======================================================================\n",
    "# DEFINE PATHS\n",
    "# ======================================================================\n",
    "ds_path = 'FaceRecognition'\n",
    "outdir = os.path.join(ds_path, 'results', 'group-level')\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# ======================================================================\n",
    "# WHICH CONTRASTS\n",
    "# ======================================================================\n",
    "contrasts = {'FamousUnfamiliar': 'Famous > Unfamiliar',\n",
    "             'UnfamiliarFamous': 'Unfamiliar > Famous',\n",
    "             'FacesScrambled': 'Faces > Scrambled',\n",
    "             'ScrambledFaces': 'Scrambled > Faces',\n",
    "             'EffectsOfInterest': 'Effects of interest'}\n",
    "\n",
    "# ======================================================================\n",
    "# PREPARE OTHER SUFF\n",
    "# ======================================================================\n",
    "\n",
    "# Initialize the BIDS layout and include the derivatives in it\n",
    "layout = BIDSLayout(os.path.join(ds_path, 'data/bids'), derivatives=True)\n",
    "layout.add_derivatives(os.path.join(ds_path, \"results\", \"first-level-2mm\"))\n",
    "\n",
    "# load a template to resample images to if needed\n",
    "template = load_mni152_template()\n",
    "\n",
    "# ======================================================================\n",
    "# PERFORM GROUP LEVEL ANALYSIS PER CONTRAST\n",
    "# ======================================================================\n",
    "\n",
    "for contrast_id, contrast_val in contrasts.items():\n",
    "    stat_files = layout.get(desc = contrast_id, suffix = 'stat', extension = '.nii.gz')\n",
    "    result_name = 'group_zmap_' + contrast_id + '_unc001k20'\n",
    "      \n",
    "    design_matrix = pd.DataFrame([1] * len(stat_files),\n",
    "                                 columns=['intercept'])\n",
    "    \n",
    "    second_level_model = SecondLevelModel(smoothing_fwhm = 8.0)\n",
    "    second_level_model = second_level_model.fit(\n",
    "        stat_files,\n",
    "        design_matrix = design_matrix)\n",
    "    \n",
    "    z_map = second_level_model.compute_contrast(output_type='z_score')\n",
    "        \n",
    "    # get threshold\n",
    "    cluster_map, threshold = threshold_stats_img(z_map, alpha=.05, height_control='fpr', cluster_threshold=20)\n",
    "    # get peak clusters    \n",
    "    peaks = get_clusters_table(z_map, stat_threshold=threshold, cluster_threshold=20)\n",
    "    \n",
    "    # if there are significant voxels, then save the img and the plot\n",
    "    try: \n",
    "        peak_xyz = peaks.loc[0, ['X','Y','Z']]\n",
    "        # create plot\n",
    "        plotting.plot_stat_map(\n",
    "            cluster_map,\n",
    "            threshold = threshold, \n",
    "            display_mode='ortho',\n",
    "            cut_coords = peak_xyz, \n",
    "            black_bg = True, \n",
    "            title = contrast_val + ' unc. p<.001, k=20'\n",
    "        )\n",
    "        \n",
    "        plt.show()\n",
    "        # save results                   \n",
    "        z_map.to_filename(os.path.join(outdir, result_name + '.nii.gz'))\n",
    "    except KeyError:\n",
    "        print('\\t', contrast_val, 'has no significant voxels.')      \n",
    "    \n",
    "    # generate and save also atlasreader output\n",
    "    create_output(\n",
    "        os.path.join(outdir, result_name + '.nii.gz'), \n",
    "        cluster_extent = 20, \n",
    "        voxel_thresh = threshold,\n",
    "        outdir = os.path.join(outdir, 'atlasreader', contrast_id)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "874.85px",
    "left": "2183px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
